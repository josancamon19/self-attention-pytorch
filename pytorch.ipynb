{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Introduction\n",
    "Will follow this guide https://docs.pytorch.org/tutorials/beginner/blitz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensors are similar to NumPyâ€™s ndarrays, except that tensors can run on GPUs or other specialized hardware\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor torch.Size([2, 2]) | torch.float32\n",
      "Tensor 2 torch.Size([2, 2]) | torch.bfloat16\n",
      "tensor([[0.6172, 0.7617],\n",
      "        [0.3438, 0.2539]], dtype=torch.bfloat16)\n",
      "------\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[7.4106e-04, 1.3401e-01, 2.6259e-01],\n",
      "        [9.8301e-01, 6.6625e-01, 5.4750e-01]])\n"
     ]
    }
   ],
   "source": [
    "# initializing tensors\n",
    "# 1. from array\n",
    "data = [[0, 2], [1, 3]]\n",
    "tensor = torch.Tensor(data)\n",
    "\n",
    "# 2. from numpy array\n",
    "data = np.array(data)\n",
    "tensor = torch.Tensor(data)\n",
    "\n",
    "# 3. from another tensor\n",
    "# - retains shape, datatype, unless overwritten\n",
    "tensor = torch.ones_like(tensor)\n",
    "print(f\"Ones Tensor {tensor.shape} | {tensor.dtype}\")\n",
    "\n",
    "tensor2 = torch.rand_like(tensor, dtype=torch.bfloat16)\n",
    "print(f\"Tensor 2 {tensor2.shape} | {tensor2.dtype}\")\n",
    "print(tensor2)\n",
    "\n",
    "# 4. based on a shape, with random/const values\n",
    "print('------')\n",
    "\n",
    "shape = (2, 3)\n",
    "ones_tensor = torch.ones(shape)\n",
    "rand_tensor = torch.rand(shape)\n",
    "\n",
    "print(ones_tensor)\n",
    "print(rand_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2]) torch.float32 cpu\n"
     ]
    }
   ],
   "source": [
    "# Attribuets\n",
    "print(tensor.shape, tensor.dtype, tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operations\n",
    "# Over 100, fuck\n",
    "# https://docs.pytorch.org/docs/stable/torch.html\n",
    "# transposing, indexing, slicing, math ops, lin alg, rand sampling, ....\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to(\"cuda\") # moving a tensor to gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7., 7., 9.],\n",
       "        [8., 4., 8.],\n",
       "        [8., 7., 2.],\n",
       "        [3., 5., 2.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.floor(torch.rand((4,3)) * 10)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([8., 4., 8.]),\n",
       " tensor([[8., 7., 2.],\n",
       "         [3., 5., 2.]]),\n",
       " tensor(8.),\n",
       " tensor([9., 8., 2., 2.]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1], a[2:], a[1,2], a[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7., 7., 9.],\n",
       "        [8., 7., 2.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor([0,2])\n",
    "a[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7., 8.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.tensor(np.arange(1))\n",
    "a[b,c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7., 7., 9.],\n",
       "        [8., 4., 8.],\n",
       "        [8., 7., 2.],\n",
       "        [3., 5., 2.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9754],\n",
       "        [0.6188],\n",
       "        [0.2690],\n",
       "        [0.9048]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.rand((4,1))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 3]), torch.Size([4, 1]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Expected size 3 but got size 1 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[87]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# requires a,b same dimension (except the one joining)\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Sizes of tensors must match except in dimension 0. Expected size 3 but got size 1 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "torch.concat((a,b), axis=0) # requires a,b same dimension (except the one joining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.0000, 7.0000, 9.0000, 0.9754],\n",
       "        [8.0000, 4.0000, 8.0000, 0.6188],\n",
       "        [8.0000, 7.0000, 2.0000, 0.2690],\n",
       "        [3.0000, 5.0000, 2.0000, 0.9048]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.concat((a,b), axis=1) # requires a,b not on concatenating one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [4, 3] at entry 0 and [4, 1] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[102]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# stack, requires equal sizes, so b should be fully 4,3\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: stack expects each tensor to be equal size, but got [4, 3] at entry 0 and [4, 1] at entry 1"
     ]
    }
   ],
   "source": [
    "torch.stack((a,b)) # stack, requires equal sizes, so b should be fully 4,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.0000, 7.0000, 9.0000, 0.9754],\n",
       "        [8.0000, 4.0000, 8.0000, 0.6188],\n",
       "        [8.0000, 7.0000, 2.0000, 0.2690],\n",
       "        [3.0000, 5.0000, 2.0000, 0.9048]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.hstack((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 3]), torch.Size([4, 1]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0616, 0.5283, 0.6863]]), torch.Size([1, 3]))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b= torch.rand(1,3)\n",
    "b, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.0000, 7.0000, 9.0000],\n",
       "        [8.0000, 4.0000, 8.0000],\n",
       "        [8.0000, 7.0000, 2.0000],\n",
       "        [3.0000, 5.0000, 2.0000],\n",
       "        [0.0616, 0.5283, 0.6863]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.vstack((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[7., 7., 9.],\n",
       "         [8., 4., 8.],\n",
       "         [8., 7., 2.],\n",
       "         [3., 5., 2.]]),\n",
       " tensor([[0.0616, 0.5283, 0.6863]]))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4310, 3.6983, 6.1768],\n",
       "        [0.4925, 2.1133, 5.4905],\n",
       "        [0.4925, 3.6983, 1.3726],\n",
       "        [0.1847, 2.6416, 1.3726]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.3060],\n",
       "        [ 8.0963],\n",
       "        [ 5.5634],\n",
       "        [ 4.1989]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a @ b.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[17., 17., 19.],\n",
       "        [18., 14., 18.],\n",
       "        [18., 17., 12.],\n",
       "        [13., 15., 12.]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in place operations\n",
    "a.add_(5) # _ underscore suffix\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro to `torch.autograd`\n",
    "https://docs.pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html\n",
    "\n",
    "What notices every operation during forward passes, and then computes gradients on backward prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /Users/joancabezas/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44.7M/44.7M [00:01<00:00, 45.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "data = torch.rand(1, 3, 64, 64)\n",
    "\n",
    "labels = torch.rand(1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model(data) # forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = (prediction - labels).sum() \n",
    "loss.backward() # backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim.step() # gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let autograd now that every op with tensor should be tracked\n",
    "a = torch.tensor([2.,3.], requires_grad=True)\n",
    "b = torch.tensor([3.,4.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = 3*a**3 - b**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zg/h51x1g8x2qb8kfgjr4xznf080000gn/T/ipykernel_34775/4229013403.py:3: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:494.)\n",
      "  Q.grad, a.grad, b.grad\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, tensor([36., 81.]), tensor([-6., -8.]))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad = torch.tensor([1.,1.])\n",
    "Q.backward(grad) # will execute chain rule, and compute gradients\n",
    "Q.grad, a.grad, b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when to .requires_grad = False?\n",
    "# frozer parameters, e.g. on finetunning we freee most params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "# Freeze all the parameters in the network\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(512, 10) # replacing the classifier layer\n",
    "\n",
    "# this would be now the only parameters with gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks\n",
    "\n",
    "`torch.nn` package\n",
    "\n",
    "https://docs.pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n",
    "\n",
    "\n",
    "- [ ] Requires a deeper understanding of CNN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Convolution layer C1: 1 input image channel, 6 output channels,\n",
    "        # 5x5 square convolution, it uses RELU activation function, and\n",
    "        # outputs a Tensor with size (N, 6, 28, 28), where N is the size of the batch\n",
    "        c1 = F.relu(self.conv1(input))\n",
    "        # Subsampling layer S2: 2x2 grid, purely functional,\n",
    "        # this layer does not have any parameter, and outputs a (N, 6, 14, 14) Tensor\n",
    "        s2 = F.max_pool2d(c1, (2, 2))\n",
    "        # Convolution layer C3: 6 input channels, 16 output channels,\n",
    "        # 5x5 square convolution, it uses RELU activation function, and\n",
    "        # outputs a (N, 16, 10, 10) Tensor\n",
    "        c3 = F.relu(self.conv2(s2))\n",
    "        # Subsampling layer S4: 2x2 grid, purely functional,\n",
    "        # this layer does not have any parameter, and outputs a (N, 16, 5, 5) Tensor\n",
    "        s4 = F.max_pool2d(c3, 2)\n",
    "        # Flatten operation: purely functional, outputs a (N, 400) Tensor\n",
    "        s4 = torch.flatten(s4, 1)\n",
    "        # Fully connected layer F5: (N, 400) Tensor input,\n",
    "        # and outputs a (N, 120) Tensor, it uses RELU activation function\n",
    "        f5 = F.relu(self.fc1(s4))\n",
    "        # Fully connected layer F6: (N, 120) Tensor input,\n",
    "        # and outputs a (N, 84) Tensor, it uses RELU activation function\n",
    "        f6 = F.relu(self.fc2(f5))\n",
    "        # Gaussian layer OUTPUT: (N, 84) Tensor input, and\n",
    "        # outputs a (N, 10) Tensor\n",
    "        output = self.fc3(f6)\n",
    "        return output\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: replace above with a simpler nn\n",
    "# defining forward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is `torch.nn.functional` `nn.Module` `nn.Parameter` `autograd.Function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore .grad_fn\n",
    "# .grad_fn.next_functions ... and so on\n",
    "# zero_grad\n",
    "# access bias, weights from layers\n",
    "# update weights computing loss manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
